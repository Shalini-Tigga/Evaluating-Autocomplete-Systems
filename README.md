# Description 
Autocompletion is a part of natural language processing, which gives statistical query completions based on user input and offers suitable suggestions for the completion of a task to make interaction easy and smooth. It saves a user from any typos, reduces keystrokes, and makes interaction better with the system as it tries to predict the next most likely word or phrase that the user may input. This paper presents a comparison of autocomplete systems, focusing on Word Embedding and N-grams model techniques, utilizing a comprehensive Wikipedia dataset for evaluation. Our findings indicate that the N-grams model outperformed other techniques, achieving an impressive accuracy of 92.4%. A detailed quantitative evaluation of the systems is provided, highlighting their performance and effectiveness in practical applications.
